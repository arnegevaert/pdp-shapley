import os
from scipy import stats
from sklearn import metrics
import numpy.typing as npt
from typing import Dict
import numpy as np
import pandas as pd


class ResultReader:
    """
    Reads and summarizes results generated by vary_fraction_variance
    """
    def __init__(self, data_dir: str, result_dir: str, model: str, baseline: str):
        """
        :param data_dir: directory containing datasets and trained models
        :param result_dir: directory containing results from vary_fraction_variance
        :param model: the model to use when extracting results
        :param baseline: the baseline (shap explainer) to compare to
        """
        self.baseline = baseline
        self.model = model
        self.result_dir = result_dir
        self.data_dir = data_dir

        self.datasets = [ds for ds in os.listdir(data_dir) if ds in os.listdir(result_dir)]

    def _load_baseline(self, dataset: str) -> npt.NDArray:
        # Shape: [num_rows, num_features, num_outputs]
        return np.load(os.path.join(self.data_dir, dataset, "shap", self.model, f"{self.baseline}.npy"))

    def _load_pddshap(self, dataset: str) -> Dict[str, npt.NDArray]:
        result_dir = os.path.join(self.result_dir, dataset, self.model)
        return {frac: np.load(os.path.join(result_dir, frac, "values.npy")) for frac in os.listdir(result_dir)}

    def get_score(self, dataset: str, score="pearson") -> Dict[str, npt.NDArray]:
        """
        Comparse the Shapley values produced by PDD-SHAP and those produced by the baseline algorithm for a given dataset.
        A dict is returned that contains an array of scores for each fraction of variance setting.
        result[frac][i,j] contains the score for fraction of variance frac, input sample i and output value j.
        Scores can be pearson correlation (score="pearson"), spearman correlation (score="spearman"), or R2 score (score="r2").

        :param dataset: the dataset to extract results from
        :param score_fn: type of score to compute
        :return: Dict: frac_variance (str) -> scores (NDArray: [num_rows, num_outputs])
        """
        if score not in ["pearson", "spearman", "r2"]:
            raise ValueError("corr_type must be pearson or spearman")
        score_fn = {
            "spearman": lambda x, y: stats.spearmanr(x,y)[0],
            "pearson": lambda x, y: stats.pearsonr(x,y)[0],
            "r2": metrics.r2_score
        }[score]
        result = {}

        baseline_values = self._load_baseline(dataset)
        pdd_values = self._load_pddshap(dataset)

        for frac in pdd_values.keys():
            #if score in ["pearson", "spearman"]:
            # Shape: [num_rows, num_outputs]
            result[frac] = np.zeros(shape=(baseline_values.shape[0], baseline_values.shape[2]))
            # TODO this can probably happen more cleanly with some map or apply function
            for i in range(baseline_values.shape[0]):
                for j in range(baseline_values.shape[2]):
                    result[frac][i, j] = score_fn(pdd_values[frac][i, :, j], baseline_values[i, :, j])
            """
            else:
                result[frac] = np.zeros(baseline_values.shape[2])
                for i in range(baseline_values.shape[2]):
                    result[frac][i] = score_fn(pdd_values[frac][:, :, i].flatten(), baseline_values[:, :, i].flatten())
            """
        return result

    def get_runtimes(self, dataset: str) -> Dict:
        """
        Returns the runtimes of sampling shapley values (for baseline) or training and inference (for PDDSHAP).
        :param dataset: the dataset to extract results from
        :return: Runtimes in the form of a dict: {
                "baseline": seconds per sample (float)
                "pddshap": {frac: {"training": seconds (float), "inference": seconds per sample (float)}}
            }
        """
        # Get baseline value
        bl_df = pd.read_csv(os.path.join(self.data_dir, dataset, "shap", self.model, "runtimes.csv"))
        baseline_values = self._load_baseline(dataset)
        num_rows = baseline_values.shape[0]
        # Extract the single entry for the baseline that we want, divide by number of rows
        result = {"baseline": bl_df.loc[bl_df['explainer'] == self.baseline]["runtime (s)"].to_numpy()[0] / num_rows}

        pdd_df = pd.read_csv(os.path.join(self.result_dir, dataset, "runtimes.csv"))
        # Get rows that correspond to the model that we want
        pdd_df = pdd_df.loc[pdd_df["model"] == self.model]
        result["pddshap"] = {}
        for index, row in pdd_df.iterrows():
            # Convert floating point fraction to string representation
            frac = str(row["fraction"]).replace('.', '')
            result["pddshap"][frac] = {"training": row["training"], "inference": row["inference"]}

        return result
